import pandas as pd

# ดึงข้อมูลจาก URL
filepath = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/FinalModule_Coursera/data/kc_house_data_NaN.csv'
df = pd.read_csv(filepath)

# แสดงชนิดข้อมูลของแต่ละคอลัมน์
df.dtypes

import pandas as pd

# โหลดข้อมูล
filepath = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/FinalModule_Coursera/data/kc_house_data_NaN.csv'
df = pd.read_csv(filepath)

# ลบคอลัมน์ 'id' และ 'Unnamed: 0' จากแกนคอลัมน์ (axis=1) และให้ผลมีผลกับ df เดิม
df.drop(["id", "Unnamed: 0"], axis=1, inplace=True)

# แสดงข้อมูลสรุปทางสถิติ
print(df.describe())

# นับจำนวนบ้านตามจำนวนชั้น (floors) ที่ไม่ซ้ำกัน
floor_counts = df["floors"].value_counts()

# แปลงเป็น DataFrame
floor_counts_df = floor_counts.to_frame()

# แสดงผล
print(floor_counts_df)

import seaborn as sns
import matplotlib.pyplot as plt

# สร้างกราฟความสัมพันธ์ระหว่าง sqft_above กับ price
sns.regplot(x="sqft_above", y="price", data=df)

# แสดงกราฟ
plt.show()

from sklearn.linear_model import LinearRegression

# กำหนดตัวแปรอิสระ (X) และ ตัวแปรตาม (y)
X = df[["sqft_living"]]
y = df["price"]

# สร้างโมเดลถดถอยเชิงเส้น
lm = LinearRegression()
lm.fit(X, y)

# คำนวณค่า R^2
r2 = lm.score(X, y)
print("R^2:", r2)

from sklearn.linear_model import LinearRegression
import pandas as pd

# Assuming 'df' is your pandas DataFrame loaded from the CSV

# Define the list of features
features = ["floors", "waterfront", "lat", "bedrooms", "sqft_basement",
            "view", "bathrooms", "sqft_living15", "sqft_above",
            "grade", "sqft_living"]

# Select the features and target variable
X = df[features]  # Independent variables
y = df["price"]   # Dependent variable

# Drop rows with any missing values in the selected features or the target variable
df_cleaned = df.dropna(subset=features + ["price"])
X_cleaned = df_cleaned[features]
y_cleaned = df_cleaned["price"]

# Create and train the Linear Regression model
lm = LinearRegression()
lm.fit(X_cleaned, y_cleaned)

# Calculate the R^2 value
r2 = lm.score(X_cleaned, y_cleaned)
print("R^2:", r2)

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LinearRegression
import pandas as pd

# Assuming 'df' is your pandas DataFrame loaded from the CSV

# กำหนดรายการคุณสมบัติ (features)
features = ["floors", "waterfront", "lat", "bedrooms", "sqft_basement",
            "view", "bathrooms", "sqft_living15", "sqft_above",
            "grade", "sqft_living"]

# เลือกข้อมูลสำหรับคุณสมบัติและตัวแปรเป้าหมาย
X = df[features]  # ตัวแปรอิสระ
y = df["price"]   # ตัวแปรตาม

# สร้าง Pipeline Object
# ขั้นตอนที่ 1: StandardScaler เพื่อปรับขนาดข้อมูลให้อยู่ในช่วงเดียวกัน
# ขั้นตอนที่ 2: PolynomialFeatures เพื่อสร้างคุณสมบัติจากพหุนาม (degree=2)
# ขั้นตอนที่ 3: LinearRegression เพื่อสร้างและเทรนโมเดลถดถอยเชิงเส้น
Input = [('scale', StandardScaler()), ('polynomial', PolynomialFeatures(include_bias=False)), ('model', LinearRegression())]
pipe = Pipeline(Input)

# ทำให้ข้อมูลที่เลือกไม่มีค่าว่าง (NaN) ก่อนนำเข้า Pipeline
# วิธีการนี้คือการลบแถวที่มีค่าว่างในคอลัมน์ features หรือ price
df_cleaned = df.dropna(subset=features + ["price"])
X_cleaned = df_cleaned[features]
y_cleaned = df_cleaned["price"]


# ฝึก Pipeline ด้วยข้อมูลที่ทำความสะอาดแล้ว
pipe.fit(X_cleaned, y_cleaned)

# คำนวณค่า R-squared ด้วยข้อมูลที่ทำความสะอาดแล้ว
r2_pipeline = pipe.score(X_cleaned, y_cleaned)
print("R^2 (Pipeline):", r2_pipeline)

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
print("done")

features =["floors", "waterfront","lat" ,"bedrooms" ,"sqft_basement" ,"view" ,"bathrooms","sqft_living15","sqft_above","grade","sqft_living"]    
X = df[features]
Y = df['price']

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=1)


print("number of test samples:", x_test.shape[0])
print("number of training samples:",x_train.shape[0])

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np # Import numpy

# Assuming 'df' is your pandas DataFrame loaded from the CSV

# Define the features and target variable
features =["floors", "waterfront","lat" ,"bedrooms" ,"sqft_basement" ,"view" ,"bathrooms","sqft_living15","sqft_above","grade","sqft_living"]
X = df[features]
Y = df['price']

# Combine X and Y for easier handling of NaNs across both
data_combined = pd.concat([X, Y], axis=1)

# Drop rows with any missing values in the combined data
data_combined_cleaned = data_combined.dropna()

# Separate X and Y again
X_cleaned = data_combined_cleaned[features]
Y_cleaned = data_combined_cleaned['price']


# Split the cleaned data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(X_cleaned, Y_cleaned, test_size=0.15, random_state=1)


# Perform a second-order polynomial transform on both the training data and testing data
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(x_train)
X_test_poly = poly.transform(x_test)

# Create and fit a Ridge regression object using the training data, setting the regularization parameter to 0.1
ridge_poly = Ridge(alpha=0.1)
ridge_poly.fit(X_train_poly, y_train)

# Calculate the R^2 utilizing the test data
r_squared_poly = ridge_poly.score(X_test_poly, y_test)
print("R^2 Value with Polynomial Features:", r_squared_poly)
